{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS1IIAS-bcb-"
   },
   "source": [
    "# Learning from Sequences: Timeseries and Text\n",
    "\n",
    "Created by Dr Ana Matran-Fernandez (amatra@essex.ac.uk) for CE888 (Data Science and Decision Making)\n",
    "\n",
    "This notebook accompanies lecture 8 and illustrates recurrent neural networks on an example of a timeseries (predicting tomorrow's temperature) and a classification problem on the IMDB text dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0myiQp20cxRK"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1646919050786,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "1J0bYBQ7_a0L"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1646921684261,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "U0NPDv7X_a0M"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KAKOLI~1\\AppData\\Local\\Temp/ipykernel_7544/567965543.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# tensorflow imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# tensorflow imports\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Bidirectional, LSTM, Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaiw_VZjbtSH"
   },
   "source": [
    "# Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1646921353848,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "iA_R1Q-K_a0N",
    "outputId": "05cb9264-7181-4711-aece-dab88fa8ea8f"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/albanda/CE888/master/lab8/weather.csv')\n",
    "df.drop(['temp_max', 'temp_min'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1646921360154,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "nzsytNAh_a0N",
    "outputId": "a669d526-4a03-478c-941d-68e188110cb6"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(df)), df['temp_avg'])\n",
    "plt.xlabel('Temporal range')\n",
    "plt.ylabel('Average temperature (C) (7 years)')\n",
    "plt.savefig('temperature_over_time.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1646921363141,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "ysbM2n99_a0N",
    "outputId": "f617f669-a323-46ed-9cd1-e01db743d378"
   },
   "outputs": [],
   "source": [
    "# Look at the first 2 years\n",
    "length = 2*365\n",
    "plt.plot(range(length), df['temp_avg'][:length])\n",
    "plt.xlabel('Temporal range')\n",
    "plt.ylabel('Average temperature (C) (2 years)')\n",
    "plt.savefig('temperature_over_time_2y.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikyqi2m7_a0O"
   },
   "source": [
    "We have clear periodicity every year. In the previous plot we saw 7 cycles (7 years). Here we see 2.\n",
    "\n",
    "Always look for periodicity in your timeseries. There will always be daily and yearly cycles. Check these patterns.\n",
    "\n",
    "Another issue with timeseries is dividing the dataset into train/validation/test sets. We definitely cannot shuffle the data, and we need to be very careful with data leakage (using data from the future)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fxuW2ne_a0P"
   },
   "source": [
    "## Data prep\n",
    "\n",
    "We'll try to predict the average temperature of tomorrow based on data from the past.\n",
    "\n",
    "To avoid data leakage, we're going to use a simple approach: use the first 50% of data for training, the next 30% for validation, and the final 20% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1646921366031,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "vofGsYen_a0P",
    "outputId": "f9b884e8-74da-421c-9e2e-ec91f561212f"
   },
   "outputs": [],
   "source": [
    "n_tr, n_val = int(0.5*len(df)), int(0.3*len(df))\n",
    "n_te = len(df) - n_tr - n_val\n",
    "print('Samples for training: %d; validation: %d; test: %d' % (n_tr, n_val, n_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1646921368468,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "lsMDT2Jq_a0P",
    "outputId": "78fb4a2f-8b30-4032-8a11-faaf1a87062b"
   },
   "outputs": [],
   "source": [
    "# Get the data from the dataframe (dropping date column)\n",
    "data = df.iloc[:, 1:].values\n",
    "print(data.shape)\n",
    "assert data.shape[0] == len(df)\n",
    "assert data.shape[1] == len(df.columns)-1, \"Are you sure you're dropping the date?\"\n",
    "# We need to normalise our time series. Calculate mean and std from TRAINING DATA ONLY. \n",
    "# We'll use it on the validation and test sets.\n",
    "mean_tr = data[:n_tr, :].mean(axis=0)\n",
    "std_tr = data[:n_tr, :].std(axis=0)\n",
    "data = (data - mean_tr) / std_tr\n",
    "\n",
    "\n",
    "y = df['temp_avg'].values.reshape(-1, 1)\n",
    "\n",
    "# index of the column that contains the avg_temp\n",
    "y_idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1646921370786,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "1VJAcdfICLi1",
    "outputId": "4e903df3-beab-431c-c54d-f365cd2897d2"
   },
   "outputs": [],
   "source": [
    "data[:20, y_idx] * std_tr[y_idx] + mean_tr[y_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1646921372060,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "xN-YJyEeCUv9",
    "outputId": "c8d85bc1-b5a1-461c-9670-92b6ae0cfd7c"
   },
   "outputs": [],
   "source": [
    "y[5:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1646921377946,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "K_JGeiAs_a0Q"
   },
   "outputs": [],
   "source": [
    "# We'll use a Dataset from keras to pass our data\n",
    "sampling_rate = 1  # we keep all data points\n",
    "sequence_length = 14  # 2 weeks to predict tomorrow's temperature\n",
    "delay = sampling_rate * sequence_length  # the target is the day after the end of the sequence\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1646921379434,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "cRDGWNYl_a0Q",
    "outputId": "412b0720-b7c4-4ff7-a92b-2b44aea2189e"
   },
   "outputs": [],
   "source": [
    "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    data[:-delay],\n",
    "    targets=y[delay:],\n",
    "    sampling_rate=sampling_rate, sequence_length=sequence_length,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0, end_index=n_tr  # first 50% for training\n",
    "    )\n",
    "\n",
    "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    data[:-delay],\n",
    "    targets=y[delay:],\n",
    "    sampling_rate=sampling_rate, sequence_length=sequence_length,\n",
    "    batch_size=batch_size,\n",
    "    start_index=n_tr, end_index=n_tr+n_val  # 50%-80% for validation\n",
    "    )\n",
    "\n",
    "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    data[:-delay],\n",
    "    targets=y[delay:],\n",
    "    sampling_rate=sampling_rate, sequence_length=sequence_length,\n",
    "    batch_size=batch_size,\n",
    "    start_index=n_tr+n_val  # last 20% for test\n",
    "    )\n",
    "\n",
    "for X, target in train_dataset:\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"target shape:\", target.shape)\n",
    "    #print(X[:, :, y_idx] * std_tr[y_idx] + mean_tr[y_idx])\n",
    "    #print(target)\n",
    "    break  # so we only print once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1646921391313,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "u_v2rAW_W4kQ"
   },
   "outputs": [],
   "source": [
    "# Function to plot history with neural networks\n",
    "def plot_hist_regression(hist, y):\n",
    "  n_ = len(hist.history['mae'])\n",
    "  plt.plot(range(1, n_+1), np.asarray(hist.history['mae']), 'bo', label='MAE on training set')\n",
    "  plt.plot(range(1, n_+1), np.asarray(hist.history['val_mae']), 'b', label='MAE on validation set')\n",
    "  plt.legend()\n",
    "  plt.xlabel(\"Epoch\") \n",
    "  plt.ylabel(\"MAE (degrees)\")\n",
    "  plt.axhline(y=y)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlhjIvZR_a0Q"
   },
   "source": [
    "## Establishing a baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rloJamyvWPWj"
   },
   "source": [
    "### Common sense, no ML baseline\n",
    "\n",
    "- Sanity check\n",
    "- To establish whether ML methods are actually any good\n",
    "\n",
    "Tomorrow's temperature is likely to be close to today's: let's predict that the temperature 24 hours from now will be equal to the temperature right now.\n",
    "\n",
    "We'll use the MAE as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2323,
     "status": "ok",
     "timestamp": 1646921396224,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "MUY5acIf_a0Q",
    "outputId": "e48cb740-8146-42a1-e5c8-3ef4cad29be9"
   },
   "outputs": [],
   "source": [
    "def naive_method(dataset, mean, std):\n",
    "    error = 0\n",
    "    samples = 0\n",
    "    count = 0\n",
    "    for X, target in dataset:\n",
    "        pred = X[:, -1, y_idx] * std + mean  # predict last available temperature and un-standardise\n",
    "        #print(X.shape, target.shape, pred.shape)  # [batch_size, sequence_length, n_feats]\n",
    "        #print(X[:, -1, y_idx] * std + mean, target)\n",
    "        error += np.sum(np.abs(pred - target))\n",
    "        samples += X.shape[0]  # batch_size\n",
    "        count += 1\n",
    "    return error / samples / batch_size # average\n",
    "\n",
    "\n",
    "print('MAE on train set = %.2f (degrees Celsius)' % naive_method(train_dataset, mean_tr[y_idx], std_tr[y_idx]))\n",
    "print('MAE on validation set = %.2f (degrees Celsius)' % naive_method(val_dataset, mean_tr[y_idx], std_tr[y_idx]))\n",
    "print('MAE on test set = %.2f (degrees Celsius)' % naive_method(test_dataset, mean_tr[y_idx], std_tr[y_idx]))\n",
    "# Save MAE on validation for later\n",
    "baseline = naive_method(val_dataset, mean_tr[y_idx], std_tr[y_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znycUtxiJmAF"
   },
   "source": [
    "This baseline achieves a validation MAE of 2.69 degrees and a test MAE of 2.85 degrees. So if we assume that tomorrow's temperature will be the same as today's, we'll be off by less than 3 degrees on average.\n",
    "\n",
    "Not too bad, but surely we can do better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c-duA1Z_a0R"
   },
   "source": [
    "### Simple ML baseline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1646921396925,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "fWGqpICHJlRe",
    "outputId": "cb73347e-9420-48e3-cb94-ad6d4a328533"
   },
   "outputs": [],
   "source": [
    "# To get some practice with neural networks, we'll try a 1-layer NN with nothing fancy.\n",
    "\n",
    "model_dense = models.Sequential()\n",
    "model_dense.add(layers.Flatten(input_shape=(sequence_length, len(df.columns)-1)))  # we need to specify the input shape or we won't be able to see the summary\n",
    "model_dense.add(layers.Dense(10, activation='relu'))\n",
    "model_dense.add(layers.Dense(1))\n",
    "\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25896,
     "status": "ok",
     "timestamp": 1646921424549,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "p0Hz1rX8LMfT",
    "outputId": "077a75d4-8522-4e99-bb68-77ead92793bb"
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "model_dense.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history_dense = model_dense.fit(train_dataset, epochs=n_epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 466,
     "status": "ok",
     "timestamp": 1646921425013,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "aBRYn-AKMCi4",
    "outputId": "ceb2c07f-9bdb-4de4-aa55-435f132ffe32"
   },
   "outputs": [],
   "source": [
    "# Plot MAE cures for validation and training\n",
    "plot_hist_regression(history_dense, baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EJywOA5NJa9"
   },
   "source": [
    "Validation loss is worse than what we had with our common-sense baseline, and we're already overfitting (MAE on training set is lower than on validation set). It turns out our previous baseline is not as easy to outperform as we thought!\n",
    "\n",
    "Remember our 'hypothesis space'? Using 2 Dense layers doesn't seem to be very useful in this case. We need other types of layers for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1646921425288,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "k6PADykQPIjq",
    "outputId": "23f2d604-3e9a-4d84-e2ef-ca9db51b321d"
   },
   "outputs": [],
   "source": [
    "# We know that CNNs take advantage of neighbouring values, so why don't we try that?\n",
    "\n",
    "# In addition to the Conv2D layers we saw last week, there are Conv1D and Conv3D layers. \n",
    "# Conv1D layers rely on 1D windows that slide across an input sequence (imagine a 1D image)\n",
    "\n",
    "model_cnn = models.Sequential()\n",
    "model_cnn.add(layers.Conv1D(8, 7, activation='relu', input_shape=(sequence_length, len(df.columns)-1)))\n",
    "model_cnn.add(layers.MaxPooling1D(2))\n",
    "model_cnn.add(layers.Conv1D(8, 3, activation='relu'))\n",
    "model_cnn.add(layers.MaxPooling1D(2))\n",
    "model_cnn.add(layers.GlobalAveragePooling1D())\n",
    "model_cnn.add(layers.Dense(1))\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21699,
     "status": "ok",
     "timestamp": 1646921446984,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "PSGRJSulQs22",
    "outputId": "85408e2c-dcf7-4e2a-dd62-fdd729216b39"
   },
   "outputs": [],
   "source": [
    "model_cnn.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history_cnn = model_cnn.fit(train_dataset, epochs=n_epochs,\n",
    "                            validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1646921447432,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "6bB6lzLYSG-u",
    "outputId": "b7afe514-34db-4c28-cf3e-c023fee0b637"
   },
   "outputs": [],
   "source": [
    "# Plot MAE cures for validation and training\n",
    "plot_hist_regression(history_cnn, baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kc2iMPSHViL1"
   },
   "source": [
    "This model isn't any better, with a validation MAE of 2.77 degrees (also worse than the 'common-sense approach' that we tried at first), and we're overfitting a bit too.\n",
    "\n",
    "Why?\n",
    "\n",
    "In timeseries, order matters a lot: the recent past is more informative than data from 5 days ago, and convolutional layers don't take advantage of this fact -- max pooling and global average pooling layers actually destroy this order information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ozUAZX__a0R"
   },
   "source": [
    "## Long Short Term Memory (LSTM) Neural Networks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1646921447710,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "2dWfiaUw_a0R",
    "outputId": "ead697e0-ef20-4f00-d29b-a4922b4c78a5"
   },
   "outputs": [],
   "source": [
    "# 1-layer LSTM\n",
    "\n",
    "model_lstm1 = models.Sequential()\n",
    "model_lstm1.add(layers.LSTM(20, input_shape=(sequence_length, len(df.columns)-1)))\n",
    "model_lstm1.add(layers.Dense(1))\n",
    "\n",
    "model_lstm1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1646921447711,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "DMst2Mp0R0Xi"
   },
   "outputs": [],
   "source": [
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34052,
     "status": "ok",
     "timestamp": 1646921481757,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "Pff2tZQHXb-z",
    "outputId": "a99e9d74-6f4f-405c-ee6c-f52f74bee07a"
   },
   "outputs": [],
   "source": [
    "model_lstm1.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history_lstm1 = model_lstm1.fit(train_dataset, epochs=n_epochs,\n",
    "                            validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1646921501329,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "hr-bgDUvXmvS",
    "outputId": "021122b9-8dea-46ed-8c19-982d441d6ccd"
   },
   "outputs": [],
   "source": [
    "# Plot MAE cures for validation and training\n",
    "plot_hist_regression(history_lstm1, baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fFZvXXUcQ67",
    "outputId": "8ac06bad-6b70-4bb6-e4f2-964253e5fa03"
   },
   "outputs": [],
   "source": [
    "print('Test MAE = %.2f degrees' % model_lstm1.evaluate(test_dataset)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYSWwI1aXvwL"
   },
   "source": [
    "Success! We finally beat the common-sense baseline! The validation MAE now is 2.12 degrees, and the test MAE is 2.27.\n",
    "\n",
    "Why do LSTM layers work? Let's go back to the slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acSYakeOcokB",
    "outputId": "2fb126f8-5e20-4748-884a-0ca6b8670f03"
   },
   "outputs": [],
   "source": [
    "# Adding dropout\n",
    "\n",
    "model_lstm2 = models.Sequential()\n",
    "model_lstm2.add(layers.LSTM(20, input_shape=(sequence_length, len(df.columns)-1), recurrent_dropout=0.25))\n",
    "model_lstm2.add(layers.Dropout(0.4))\n",
    "model_lstm2.add(layers.Dense(1))\n",
    "\n",
    "model_lstm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvRnf9TWSWf9",
    "outputId": "af247ccc-7255-4ca4-b8db-192913fc835a"
   },
   "outputs": [],
   "source": [
    "model_lstm2.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history_lstm2 = model_lstm2.fit(train_dataset, epochs=n_epochs,\n",
    "                            validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "cWpm-j9iSck1",
    "outputId": "cf66d132-b95f-456c-d6a4-86c9d28a5aef"
   },
   "outputs": [],
   "source": [
    "# Plot MAE cures for validation and training\n",
    "plot_hist_regression(history_lstm2, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rAIQrQDVSmSM",
    "outputId": "8008e969-28d8-48e4-a402-720ada6f59a8"
   },
   "outputs": [],
   "source": [
    "print('Test MAE = %.2f degrees' % model_lstm2.evaluate(test_dataset)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3OrpvE3S4gM"
   },
   "source": [
    "Note that validation set MAE is now lower than MAE on training set -- no longer overfitting. Validation MAE is 2.16 and test MAE is also 2.16.\n",
    "\n",
    "NOTE: This is a very simple dataset with very small differences in performance between different models.  You'll just have to take my word for it that *in general* this approach works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jq_ZDTttTX6_",
    "outputId": "3178ee55-e729-4191-b765-4e81bec2a291"
   },
   "outputs": [],
   "source": [
    "# Performance in the previous figure can (maybe) still be improved\n",
    "# Let's try to add some more layers -- we can do this now that we're no longer overfitting\n",
    "\n",
    "model_lstm3 = models.Sequential()\n",
    "model_lstm3.add(layers.LSTM(20, input_shape=(sequence_length, len(df.columns)-1), recurrent_dropout=0.25, return_sequences=True))  # NEW!\n",
    "model_lstm3.add(layers.LSTM(20, input_shape=(sequence_length, len(df.columns)-1), recurrent_dropout=0.25))  # NEW!!\n",
    "model_lstm3.add(layers.Dropout(0.4))\n",
    "model_lstm3.add(layers.Dense(1))\n",
    "model_lstm3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xQXChtNUxzh",
    "outputId": "47adf7db-d1ea-4cbe-f2b2-2ea09bbbb96f"
   },
   "outputs": [],
   "source": [
    "model_lstm3.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_mae', patience=2)]\n",
    "\n",
    "history_lstm3 = model_lstm3.fit(train_dataset, epochs=60,  # increased number of epochs\n",
    "                            validation_data=val_dataset,\n",
    "                            callbacks=callbacks)  # but added early stopping callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "PtFfB3YaU4k3",
    "outputId": "eb5fd379-362d-4cb4-d846-d6d264dccab1"
   },
   "outputs": [],
   "source": [
    "# Plot MAE cures for validation and training\n",
    "plot_hist_regression(history_lstm3, baseline)\n",
    "print('Test MAE = %.2f degrees' % model_lstm3.evaluate(test_dataset)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUJqRqp1XJnL"
   },
   "source": [
    "Validation MAE = 1.92 degrees\n",
    "\n",
    "Test MAE = 1.89 degrees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGEuNqw2csXj"
   },
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtv0EjsTbwvm"
   },
   "source": [
    "## Data prep\n",
    "\n",
    "We'll try to predict whether the review for a movie is positive or negative looking only at the text of the review.\n",
    "\n",
    "We'll use the IMDB text dataset for this task, which is available on `keras.datasets` and described [here](https://keras.io/api/datasets/imdb/). \n",
    "\n",
    "We'll merge the training and test sets and use 60% for training, 20% for validation, and 20% for testing.\n",
    "\n",
    "\n",
    "As this is a binary classificationp problem, we'll use the binary cross entropy loss function. We will keep track of accuracy when training and evaluating the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1646921573674,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "i-mH-8IGwGo1"
   },
   "outputs": [],
   "source": [
    "def plot_hist_classif(hist):\n",
    "  n_ = len(hist.history['accuracy'])\n",
    "  plt.plot(range(1, n_+1), 100*np.asarray(hist.history['accuracy']), 'bo', label='Accuracy on training set')\n",
    "  plt.plot(range(1, n_+1), 100*np.asarray(hist.history['val_accuracy']), 'b', label='Accuracy on validation set')\n",
    "  plt.legend()\n",
    "  plt.xlabel(\"Epoch\") \n",
    "  plt.ylabel(\"Accuracy\")\n",
    "  plt.ylim(0, 100)\n",
    "  plt.axhline(y=50)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5088,
     "status": "ok",
     "timestamp": 1646921580159,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "4TW3Vg49n5V-",
    "outputId": "eecdf478-679f-4fe4-fffa-b7d4663a0ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KAKOLI~1\\AppData\\Local\\Temp/ipykernel_7544/2684210302.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loading data...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Load dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train sequences'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test sequences'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "max_features = 15000  # only consider the top 15k words\n",
    "maxlen = 500  # first 500 words of each review\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences', x_train.shape)\n",
    "print(len(x_test), 'test sequences', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1646921580159,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "8ApTb-jYtSOm",
    "outputId": "82899a08-45b5-4d6a-aef8-71e5f93e1030"
   },
   "outputs": [],
   "source": [
    "# How balanced is this dataset?\n",
    "print(np.sum(y_train)/len(y_train))\n",
    "print(np.sum(y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1646921582432,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "Z53Fbicqr8tm",
    "outputId": "d944c613-47f9-4be7-a011-50d5a6bdb44c"
   },
   "outputs": [],
   "source": [
    "# Merge the two datasets and divide: 60% for training, 20% validation, 20% test\n",
    "x_, y_ = np.concatenate((x_train, x_test)), np.concatenate((y_train, y_test))\n",
    "print(x_.shape, y_.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_, y_, test_size=0.4, random_state=10)  # 60/40 split\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=10)  # 50/50 split\n",
    "print(len(x_train), 'train sequences', x_train.shape)\n",
    "print(len(x_val), 'validation sequences', x_val.shape)\n",
    "print(len(x_test), 'test sequences', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1646921587614,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "5v_Hy-r8o8pR",
    "outputId": "fe65ea7b-8cb7-4a81-dadf-40a359944c54"
   },
   "outputs": [],
   "source": [
    "x_train[0][:10]  # numbers!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1646921589749,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "rgEgNSLBpFwh",
    "outputId": "d7063bef-98e4-4223-851c-a05ea4c0a064"
   },
   "outputs": [],
   "source": [
    "# We can explore what one of the reviews looks like at this point.\n",
    "\n",
    "# Retrieve the word index file that maps words to indices\n",
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "# Reverse the word index to obtain a dict mapping indices to words (which is what we have)\n",
    "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
    "# Decode the first sequence in the dataset\n",
    "decoded_sequence = \" \".join(inverted_word_index[i] for i in x_train[0])\n",
    "decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1281,
     "status": "ok",
     "timestamp": 1646921593306,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "ibmO0V-gcthG",
    "outputId": "742b7e07-1207-4460-a04c-83dd4ace42bd"
   },
   "outputs": [],
   "source": [
    "# Let's ensure all sequences have the same length through padding\n",
    "# - shorter reviews are padded with 0's\n",
    "# - longer reviews are cut\n",
    "print('Pad sequences')\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_val shape:', x_val.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1646921594926,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "sBpQpwBAk44H",
    "outputId": "194a6aad-3308-41f6-d86f-b62d22dd9440"
   },
   "outputs": [],
   "source": [
    "# Basic feedforward model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8c7tCS5vrC3",
    "outputId": "aab08477-7bd5-4394-b052-3faa0d266096"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=20, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "dKBVw5mHv_oX",
    "outputId": "01b16817-5689-4137-d46b-8275b712e986"
   },
   "outputs": [],
   "source": [
    "plot_hist_classif(history)\n",
    "print('Test Accuracy = %.2f' % model.evaluate(x_test, y_test)[1])  # overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ieh7Wl9Pwh8V",
    "outputId": "7e4d2bbc-b62c-407d-ee81-e5d62d9caa3a"
   },
   "outputs": [],
   "source": [
    "# Let's try an RNN\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 64))\n",
    "model.add(layers.LSTM(128, return_sequences=False))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "Sd54xZMmxKBQ",
    "outputId": "96c092e9-eea3-4080-b720-31885daecd83"
   },
   "outputs": [],
   "source": [
    "# This model will take a long time to train, so we add an early stopping criterion\n",
    "# N.B: It's actually much faster to train WITHOUT A GPU!!\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=2)]\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=20, validation_data=(x_val, y_val), callbacks=callbacks)\n",
    "plot_hist_classif(history)\n",
    "print('Test Accuracy = %.2f' % model.evaluate(x_test, y_test)[1])\n",
    "# Note that we're still overfitting, but this is just an example of use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzZhXm5gkz_g"
   },
   "source": [
    "## Your turn!\n",
    "\n",
    "Implement a bidirectional RNN that can outperform the LSTM model we had above.\n",
    "\n",
    "A starting skeleton could be:\n",
    " \n",
    "*   Embedding layer with an output dimension of 64\n",
    "*   Bidirectional layer with a 32-neuron LSTM layer\n",
    "*   Dense layer with 1 neuron and a sigmoid activation\n",
    "\n",
    "Some suggestions:\n",
    "\n",
    "- Change the sizes of the layers (i.e., the numbers of neurons)\n",
    "- Add dropout\n",
    "- Add other recurrent and/or bidirectional layers\n",
    "\n",
    "Once you have a model that scores over 90% on the validation set, check its performance on the test set and upload it on the code checker in Moodle.\n",
    "\n",
    "Note that the model I'm suggesting above will be able to reach the desired performance, but it will show signs of overfitting. Can you do it by adding regularization (dropout, smaller network) so you don't overfit?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "executionInfo": {
     "elapsed": 904875,
     "status": "ok",
     "timestamp": 1646925200493,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "jCHOC7dyadaj",
    "outputId": "c414ef73-7d19-4d50-fa26-e0ca58c6dbc6"
   },
   "outputs": [],
   "source": [
    "n_ = 3  # number of epochs. You can edit this\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 64))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# I DON'T RECOMMEND THAT YOU CHANGE CODE AFTER THIS POINT\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# This model will take a long time to train, so we add an early stopping criterion\n",
    "# I've also added a ModelCheckpoint that will save the best model according to val_accuracy regardless of whether we continue training\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=1),\n",
    "             ModelCheckpoint(\"model.keras\", save_best_only=True, monitor=\"val_accuracy\", mode='max')]\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=n_, \n",
    "                    validation_data=(x_val, y_val), \n",
    "                    callbacks=callbacks)\n",
    "plot_hist_classif(history)\n",
    "model = keras.models.load_model(\"model.keras\")\n",
    "print('Test Accuracy = %.2f' % model.evaluate(x_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "error",
     "timestamp": 1646925200493,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "ZFBmg66_CR7y",
    "outputId": "bdf45c43-76ff-49f0-80e7-391f6abd3e09"
   },
   "outputs": [],
   "source": [
    "if model.count_params() > 1000000:\n",
    "    print(\"Due to memory constraints on Moodle, the lab quiz has a 10MB limit on your model size, so you need to use a smaller model to validate through the auto-marker.\")\n",
    "\n",
    "if history.history[\"val_accuracy\"][-1] > 0.9:\n",
    "    print(\"Your model is accurate enough!\")\n",
    "\n",
    "else:\n",
    "    print(\"Accuracy is below the threshold!\")\n",
    "    raise Exception(\"Your model isn't accurate enough to pass the progress checker!\")\n",
    "# Save the model into a local folder\n",
    "keras.models.save_model(model, \"Model.h5\",save_format='h5')\n",
    "print('Model saved! You can now upload it to the lab quiz.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hv7PyBQQsXav"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WlhjIvZR_a0Q",
    "rloJamyvWPWj",
    "7c-duA1Z_a0R",
    "3ozUAZX__a0R"
   ],
   "name": "Copy of rnn.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/albanda/CE888/blob/master/lab8/rnn.ipynb",
     "timestamp": 1646925252038
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
