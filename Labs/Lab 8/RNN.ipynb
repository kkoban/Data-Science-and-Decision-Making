{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS1IIAS-bcb-"
   },
   "source": [
    "# Learning from Sequences: Timeseries and Text\n",
    "\n",
    "Created by Dr Ana Matran-Fernandez (amatra@essex.ac.uk) for CE888 (Data Science and Decision Making)\n",
    "\n",
    "This notebook accompanies lecture 8 and illustrates recurrent neural networks on an example of a timeseries (predicting tomorrow's temperature) and a classification problem on the IMDB text dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0myiQp20cxRK"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-win_amd64.whl (438.0 MB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp39-cp39-win_amd64.whl (3.4 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.0-py2.py3-none-any.whl (156 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kakoli banik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=43f1712fe899bb39a3a746016ab443fb3ed7889cd025c65a2cb596d955efe50e\n",
      "  Stored in directory: c:\\users\\kakoli banik\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1646919050786,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "1J0bYBQ7_a0L"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1646921684261,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "U0NPDv7X_a0M"
   },
   "outputs": [],
   "source": [
    "# tensorflow imports\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Bidirectional, LSTM, Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaiw_VZjbtSH"
   },
   "source": [
    "# Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1646921353848,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "iA_R1Q-K_a0N",
    "outputId": "05cb9264-7181-4711-aece-dab88fa8ea8f"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/albanda/CE888/master/lab8/weather.csv')\n",
    "df.drop(['temp_max', 'temp_min'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1646921360154,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "nzsytNAh_a0N",
    "outputId": "a669d526-4a03-478c-941d-68e188110cb6"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(df)), df['temp_avg'])\n",
    "plt.xlabel('Temporal range')\n",
    "plt.ylabel('Average temperature (C) (7 years)')\n",
    "plt.savefig('temperature_over_time.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1646921363141,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "ysbM2n99_a0N",
    "outputId": "f617f669-a323-46ed-9cd1-e01db743d378"
   },
   "outputs": [],
   "source": [
    "# Look at the first 2 years\n",
    "length = 2*365\n",
    "plt.plot(range(length), df['temp_avg'][:length])\n",
    "plt.xlabel('Temporal range')\n",
    "plt.ylabel('Average temperature (C) (2 years)')\n",
    "plt.savefig('temperature_over_time_2y.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikyqi2m7_a0O"
   },
   "source": [
    "We have clear periodicity every year. In the previous plot we saw 7 cycles (7 years). Here we see 2.\n",
    "\n",
    "Always look for periodicity in your timeseries. There will always be daily and yearly cycles. Check these patterns.\n",
    "\n",
    "Another issue with timeseries is dividing the dataset into train/validation/test sets. We definitely cannot shuffle the data, and we need to be very careful with data leakage (using data from the future)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fxuW2ne_a0P"
   },
   "source": [
    "## Data prep\n",
    "\n",
    "We'll try to predict the average temperature of tomorrow based on data from the past.\n",
    "\n",
    "To avoid data leakage, we're going to use a simple approach: use the first 50% of data for training, the next 30% for validation, and the final 20% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1646921366031,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "vofGsYen_a0P",
    "outputId": "f9b884e8-74da-421c-9e2e-ec91f561212f"
   },
   "outputs": [],
   "source": [
    "n_tr, n_val = int(0.5*len(df)), int(0.3*len(df))\n",
    "n_te = len(df) - n_tr - n_val\n",
    "print('Samples for training: %d; validation: %d; test: %d' % (n_tr, n_val, n_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1646921368468,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "lsMDT2Jq_a0P",
    "outputId": "78fb4a2f-8b30-4032-8a11-faaf1a87062b"
   },
   "outputs": [],
   "source": [
    "# Get the data from the dataframe (dropping date column)\n",
    "data = df.iloc[:, 1:].values\n",
    "print(data.shape)\n",
    "assert data.shape[0] == len(df)\n",
    "assert data.shape[1] == len(df.columns)-1, \"Are you sure you're dropping the date?\"\n",
    "# We need to normalise our time series. Calculate mean and std from TRAINING DATA ONLY. \n",
    "# We'll use it on the validation and test sets.\n",
    "mean_tr = data[:n_tr, :].mean(axis=0)\n",
    "std_tr = data[:n_tr, :].std(axis=0)\n",
    "data = (data - mean_tr) / std_tr\n",
    "\n",
    "\n",
    "y = df['temp_avg'].values.reshape(-1, 1)\n",
    "\n",
    "# index of the column that contains the avg_temp\n",
    "y_idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1646921370786,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "1VJAcdfICLi1",
    "outputId": "4e903df3-beab-431c-c54d-f365cd2897d2"
   },
   "outputs": [],
   "source": [
    "data[:20, y_idx] * std_tr[y_idx] + mean_tr[y_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1646921372060,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "xN-YJyEeCUv9",
    "outputId": "c8d85bc1-b5a1-461c-9670-92b6ae0cfd7c"
   },
   "outputs": [],
   "source": [
    "y[5:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1646921377946,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "K_JGeiAs_a0Q"
   },
   "outputs": [],
   "source": [
    "# We'll use a Dataset from keras to pass our data\n",
    "sampling_rate = 1  # we keep all data points\n",
    "sequence_length = 14  # 2 weeks to predict tomorrow's temperature\n",
    "delay = sampling_rate * sequence_length  # the target is the day after the end of the sequence\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1646921379434,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "cRDGWNYl_a0Q",
    "outputId": "412b0720-b7c4-4ff7-a92b-2b44aea2189e"
   },
   "outputs": [],
   "source": [
    "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    data[:-delay],\n",
    "    targets=y[delay:],\n",
    "    sampling_rate=sampling_rate, sequence_length=sequence_length,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0, end_index=n_tr  # first 50% for training\n",
    "    )\n",
    "\n",
    "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    data[:-delay],\n",
    "    targets=y[delay:],\n",
    "    sampling_rate=sampling_rate, sequence_length=sequence_length,\n",
    "    batch_size=batch_size,\n",
    "    start_index=n_tr, end_index=n_tr+n_val  # 50%-80% for validation\n",
    "    )\n",
    "\n",
    "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    data[:-delay],\n",
    "    targets=y[delay:],\n",
    "    sampling_rate=sampling_rate, sequence_length=sequence_length,\n",
    "    batch_size=batch_size,\n",
    "    start_index=n_tr+n_val  # last 20% for test\n",
    "    )\n",
    "\n",
    "for X, target in train_dataset:\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"target shape:\", target.shape)\n",
    "    #print(X[:, :, y_idx] * std_tr[y_idx] + mean_tr[y_idx])\n",
    "    #print(target)\n",
    "    break  # so we only print once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1646921391313,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "u_v2rAW_W4kQ"
   },
   "outputs": [],
   "source": [
    "# Function to plot history with neural networks\n",
    "def plot_hist_regression(hist, y):\n",
    "  n_ = len(hist.history['mae'])\n",
    "  plt.plot(range(1, n_+1), np.asarray(hist.history['mae']), 'bo', label='MAE on training set')\n",
    "  plt.plot(range(1, n_+1), np.asarray(hist.history['val_mae']), 'b', label='MAE on validation set')\n",
    "  plt.legend()\n",
    "  plt.xlabel(\"Epoch\") \n",
    "  plt.ylabel(\"MAE (degrees)\")\n",
    "  plt.axhline(y=y)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlhjIvZR_a0Q"
   },
   "source": [
    "## Establishing a baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rloJamyvWPWj"
   },
   "source": [
    "### Common sense, no ML baseline\n",
    "\n",
    "- Sanity check\n",
    "- To establish whether ML methods are actually any good\n",
    "\n",
    "Tomorrow's temperature is likely to be close to today's: let's predict that the temperature 24 hours from now will be equal to the temperature right now.\n",
    "\n",
    "We'll use the MAE as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2323,
     "status": "ok",
     "timestamp": 1646921396224,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "MUY5acIf_a0Q",
    "outputId": "e48cb740-8146-42a1-e5c8-3ef4cad29be9"
   },
   "outputs": [],
   "source": [
    "def naive_method(dataset, mean, std):\n",
    "    error = 0\n",
    "    samples = 0\n",
    "    count = 0\n",
    "    for X, target in dataset:\n",
    "        pred = X[:, -1, y_idx] * std + mean  # predict last available temperature and un-standardise\n",
    "        #print(X.shape, target.shape, pred.shape)  # [batch_size, sequence_length, n_feats]\n",
    "        #print(X[:, -1, y_idx] * std + mean, target)\n",
    "        error += np.sum(np.abs(pred - target))\n",
    "        samples += X.shape[0]  # batch_size\n",
    "        count += 1\n",
    "    return error / samples / batch_size # average\n",
    "\n",
    "\n",
    "print('MAE on train set = %.2f (degrees Celsius)' % naive_method(train_dataset, mean_tr[y_idx], std_tr[y_idx]))\n",
    "print('MAE on validation set = %.2f (degrees Celsius)' % naive_method(val_dataset, mean_tr[y_idx], std_tr[y_idx]))\n",
    "print('MAE on test set = %.2f (degrees Celsius)' % naive_method(test_dataset, mean_tr[y_idx], std_tr[y_idx]))\n",
    "# Save MAE on validation for later\n",
    "baseline = naive_method(val_dataset, mean_tr[y_idx], std_tr[y_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znycUtxiJmAF"
   },
   "source": [
    "This baseline achieves a validation MAE of 2.69 degrees and a test MAE of 2.85 degrees. So if we assume that tomorrow's temperature will be the same as today's, we'll be off by less than 3 degrees on average.\n",
    "\n",
    "Not too bad, but surely we can do better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c-duA1Z_a0R"
   },
   "source": [
    "### Simple ML baseline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1646921396925,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "fWGqpICHJlRe",
    "outputId": "cb73347e-9420-48e3-cb94-ad6d4a328533"
   },
   "outputs": [],
   "source": [
    "# To get some practice with neural networks, we'll try a 1-layer NN with nothing fancy.\n",
    "\n",
    "model_dense = models.Sequential()\n",
    "model_dense.add(layers.Flatten(input_shape=(sequence_length, len(df.columns)-1)))  # we need to specify the input shape or we won't be able to see the summary\n",
    "model_dense.add(layers.Dense(10, activation='relu'))\n",
    "model_dense.add(layers.Dense(1))\n",
    "\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25896,
     "status": "ok",
     "timestamp": 1646921424549,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "p0Hz1rX8LMfT",
    "outputId": "077a75d4-8522-4e99-bb68-77ead92793bb"
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "model_dense.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history_dense = model_dense.fit(train_dataset, epochs=n_epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 466,
     "status": "ok",
     "timestamp": 1646921425013,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "aBRYn-AKMCi4",
    "outputId": "ceb2c07f-9bdb-4de4-aa55-435f132ffe32"
   },
   "outputs": [],
   "source": [
    "# Plot MAE cures for validation and training\n",
    "plot_hist_regression(history_dense, baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EJywOA5NJa9"
   },
   "source": [
    "Validation loss is worse than what we had with our common-sense baseline, and we're already overfitting (MAE on training set is lower than on validation set). It turns out our previous baseline is not as easy to outperform as we thought!\n",
    "\n",
    "Remember our 'hypothesis space'? Using 2 Dense layers doesn't seem to be very useful in this case. We need other types of layers for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1646921425288,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "k6PADykQPIjq",
    "outputId": "23f2d604-3e9a-4d84-e2ef-ca9db51b321d"
   },
   "outputs": [],
   "source": [
    "# We know that CNNs take advantage of neighbouring values, so why don't we try that?\n",
    "\n",
    "# In addition to the Conv2D layers we saw last week, there are Conv1D and Conv3D layers. \n",
    "# Conv1D layers rely on 1D windows that slide across an input sequence (imagine a 1D image)\n",
    "\n",
    "model_cnn = models.Sequential()\n",
    "model_cnn.add(layers.Conv1D(8, 7, activation='relu', input_shape=(sequence_length, len(df.columns)-1)))\n",
    "model_cnn.add(layers.MaxPooling1D(2))\n",
    "model_cnn.add(layers.Conv1D(8, 3, activation='relu'))\n",
    "model_cnn.add(layers.MaxPooling1D(2))\n",
    "model_cnn.add(layers.GlobalAveragePooling1D())\n",
    "model_cnn.add(layers.Dense(1))\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21699,
     "status": "ok",
     "timestamp": 1646921446984,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "PSGRJSulQs22",
    "outputId": "85408e2c-dcf7-4e2a-dd62-fdd729216b39"
   },
   "outputs": [],
   "source": [
    "model_cnn.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history_cnn = model_cnn.fit(train_dataset, epochs=n_epochs,\n",
    "                            validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1646921447432,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "6bB6lzLYSG-u",
    "outputId": "b7afe514-34db-4c28-cf3e-c023fee0b637"
   },
   "outputs": [],
   "source": [
    "# Plot MAE cures for validation and training\n",
    "plot_hist_regression(history_cnn, baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kc2iMPSHViL1"
   },
   "source": [
    "This model isn't any better, with a validation MAE of 2.77 degrees (also worse than the 'common-sense approach' that we tried at first), and we're overfitting a bit too.\n",
    "\n",
    "Why?\n",
    "\n",
    "In timeseries, order matters a lot: the recent past is more informative than data from 5 days ago, and convolutional layers don't take advantage of this fact -- max pooling and global average pooling layers actually destroy this order information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ozUAZX__a0R"
   },
   "source": [
    "## Long Short Term Memory (LSTM) Neural Networks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1646921447710,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "2dWfiaUw_a0R",
    "outputId": "ead697e0-ef20-4f00-d29b-a4922b4c78a5"
   },
   "outputs": [],
   "source": [
    "# 1-layer LSTM\n",
    "\n",
    "model_lstm1 = models.Sequential()\n",
    "model_lstm1.add(layers.LSTM(20, input_shape=(sequence_length, len(df.columns)-1)))\n",
    "model_lstm1.add(layers.Dense(1))\n",
    "\n",
    "model_lstm1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1646921447711,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "DMst2Mp0R0Xi"
   },
   "outputs": [],
   "source": [
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34052,
     "status": "ok",
     "timestamp": 1646921481757,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "Pff2tZQHXb-z",
    "outputId": "a99e9d74-6f4f-405c-ee6c-f52f74bee07a"
   },
   "outputs": [],
   "source": [
    "model_lstm1.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history_lstm1 = model_lstm1.fit(train_dataset, epochs=n_epochs,\n",
    "                            validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1646921501329,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "hr-bgDUvXmvS",
    "outputId": "021122b9-8dea-46ed-8c19-982d441d6ccd"
   },
   "outputs": [],
   "source": [
    "# Plot MAE cures for validation and training\n",
    "plot_hist_regression(history_lstm1, baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fFZvXXUcQ67",
    "outputId": "8ac06bad-6b70-4bb6-e4f2-964253e5fa03"
   },
   "outputs": [],
   "source": [
    "print('Test MAE = %.2f degrees' % model_lstm1.evaluate(test_dataset)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYSWwI1aXvwL"
   },
   "source": [
    "Success! We finally beat the common-sense baseline! The validation MAE now is 2.12 degrees, and the test MAE is 2.27.\n",
    "\n",
    "Why do LSTM layers work? Let's go back to the slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acSYakeOcokB",
    "outputId": "2fb126f8-5e20-4748-884a-0ca6b8670f03"
   },
   "outputs": [],
   "source": [
    "# Adding dropout\n",
    "\n",
    "model_lstm2 = models.Sequential()\n",
    "model_lstm2.add(layers.LSTM(20, input_shape=(sequence_length, len(df.columns)-1), recurrent_dropout=0.25))\n",
    "model_lstm2.add(layers.Dropout(0.4))\n",
    "model_lstm2.add(layers.Dense(1))\n",
    "\n",
    "model_lstm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvRnf9TWSWf9",
    "outputId": "af247ccc-7255-4ca4-b8db-192913fc835a"
   },
   "outputs": [],
   "source": [
    "model_lstm2.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history_lstm2 = model_lstm2.fit(train_dataset, epochs=n_epochs,\n",
    "                            validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "cWpm-j9iSck1",
    "outputId": "cf66d132-b95f-456c-d6a4-86c9d28a5aef"
   },
   "outputs": [],
   "source": [
    "# Plot MAE cures for validation and training\n",
    "plot_hist_regression(history_lstm2, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rAIQrQDVSmSM",
    "outputId": "8008e969-28d8-48e4-a402-720ada6f59a8"
   },
   "outputs": [],
   "source": [
    "print('Test MAE = %.2f degrees' % model_lstm2.evaluate(test_dataset)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3OrpvE3S4gM"
   },
   "source": [
    "Note that validation set MAE is now lower than MAE on training set -- no longer overfitting. Validation MAE is 2.16 and test MAE is also 2.16.\n",
    "\n",
    "NOTE: This is a very simple dataset with very small differences in performance between different models.  You'll just have to take my word for it that *in general* this approach works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jq_ZDTttTX6_",
    "outputId": "3178ee55-e729-4191-b765-4e81bec2a291"
   },
   "outputs": [],
   "source": [
    "# Performance in the previous figure can (maybe) still be improved\n",
    "# Let's try to add some more layers -- we can do this now that we're no longer overfitting\n",
    "\n",
    "model_lstm3 = models.Sequential()\n",
    "model_lstm3.add(layers.LSTM(20, input_shape=(sequence_length, len(df.columns)-1), recurrent_dropout=0.25, return_sequences=True))  # NEW!\n",
    "model_lstm3.add(layers.LSTM(20, input_shape=(sequence_length, len(df.columns)-1), recurrent_dropout=0.25))  # NEW!!\n",
    "model_lstm3.add(layers.Dropout(0.4))\n",
    "model_lstm3.add(layers.Dense(1))\n",
    "model_lstm3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xQXChtNUxzh",
    "outputId": "47adf7db-d1ea-4cbe-f2b2-2ea09bbbb96f"
   },
   "outputs": [],
   "source": [
    "model_lstm3.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_mae', patience=2)]\n",
    "\n",
    "history_lstm3 = model_lstm3.fit(train_dataset, epochs=60,  # increased number of epochs\n",
    "                            validation_data=val_dataset,\n",
    "                            callbacks=callbacks)  # but added early stopping callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "PtFfB3YaU4k3",
    "outputId": "eb5fd379-362d-4cb4-d846-d6d264dccab1"
   },
   "outputs": [],
   "source": [
    "# Plot MAE cures for validation and training\n",
    "plot_hist_regression(history_lstm3, baseline)\n",
    "print('Test MAE = %.2f degrees' % model_lstm3.evaluate(test_dataset)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUJqRqp1XJnL"
   },
   "source": [
    "Validation MAE = 1.92 degrees\n",
    "\n",
    "Test MAE = 1.89 degrees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGEuNqw2csXj"
   },
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtv0EjsTbwvm"
   },
   "source": [
    "## Data prep\n",
    "\n",
    "We'll try to predict whether the review for a movie is positive or negative looking only at the text of the review.\n",
    "\n",
    "We'll use the IMDB text dataset for this task, which is available on `keras.datasets` and described [here](https://keras.io/api/datasets/imdb/). \n",
    "\n",
    "We'll merge the training and test sets and use 60% for training, 20% for validation, and 20% for testing.\n",
    "\n",
    "\n",
    "As this is a binary classificationp problem, we'll use the binary cross entropy loss function. We will keep track of accuracy when training and evaluating the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1646921573674,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "i-mH-8IGwGo1"
   },
   "outputs": [],
   "source": [
    "def plot_hist_classif(hist):\n",
    "  n_ = len(hist.history['accuracy'])\n",
    "  plt.plot(range(1, n_+1), 100*np.asarray(hist.history['accuracy']), 'bo', label='Accuracy on training set')\n",
    "  plt.plot(range(1, n_+1), 100*np.asarray(hist.history['val_accuracy']), 'b', label='Accuracy on validation set')\n",
    "  plt.legend()\n",
    "  plt.xlabel(\"Epoch\") \n",
    "  plt.ylabel(\"Accuracy\")\n",
    "  plt.ylim(0, 100)\n",
    "  plt.axhline(y=50)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5088,
     "status": "ok",
     "timestamp": 1646921580159,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "4TW3Vg49n5V-",
    "outputId": "eecdf478-679f-4fe4-fffa-b7d4663a0ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n",
      "17473536/17464789 [==============================] - 1s 0us/step\n",
      "25000 train sequences (25000,)\n",
      "25000 test sequences (25000,)\n"
     ]
    }
   ],
   "source": [
    "max_features = 15000  # only consider the top 15k words\n",
    "maxlen = 500  # first 500 words of each review\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences', x_train.shape)\n",
    "print(len(x_test), 'test sequences', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1646921580159,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "8ApTb-jYtSOm",
    "outputId": "82899a08-45b5-4d6a-aef8-71e5f93e1030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# How balanced is this dataset?\n",
    "print(np.sum(y_train)/len(y_train))\n",
    "print(np.sum(y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1646921582432,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "Z53Fbicqr8tm",
    "outputId": "d944c613-47f9-4be7-a011-50d5a6bdb44c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,) (50000,)\n",
      "30000 train sequences (30000,)\n",
      "10000 validation sequences (10000,)\n",
      "10000 test sequences (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Merge the two datasets and divide: 60% for training, 20% validation, 20% test\n",
    "x_, y_ = np.concatenate((x_train, x_test)), np.concatenate((y_train, y_test))\n",
    "print(x_.shape, y_.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_, y_, test_size=0.4, random_state=10)  # 60/40 split\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=10)  # 50/50 split\n",
    "print(len(x_train), 'train sequences', x_train.shape)\n",
    "print(len(x_val), 'validation sequences', x_val.shape)\n",
    "print(len(x_test), 'test sequences', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1646921587614,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "5v_Hy-r8o8pR",
    "outputId": "fe65ea7b-8cb7-4a81-dadf-40a359944c54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 11531, 186, 8, 28, 6, 6482, 7, 269, 4042]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][:10]  # numbers!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1646921589749,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "rgEgNSLBpFwh",
    "outputId": "d7063bef-98e4-4223-851c-a05ea4c0a064"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"the lilly horror in one is fatale br looks meaningless in bronson be showing as you debut film ample to and ingredients zombi ample they for series and thought she's all manipulate and believing in j show look early last quote desire tight interesting that's kind out is far shelter but of frame br and\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can explore what one of the reviews looks like at this point.\n",
    "\n",
    "# Retrieve the word index file that maps words to indices\n",
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "# Reverse the word index to obtain a dict mapping indices to words (which is what we have)\n",
    "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
    "# Decode the first sequence in the dataset\n",
    "decoded_sequence = \" \".join(inverted_word_index[i] for i in x_train[0])\n",
    "decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1281,
     "status": "ok",
     "timestamp": 1646921593306,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "ibmO0V-gcthG",
    "outputId": "742b7e07-1207-4460-a04c-83dd4ace42bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences\n",
      "x_train shape: (30000, 500)\n",
      "x_val shape: (10000, 500)\n",
      "x_test shape: (10000, 500)\n"
     ]
    }
   ],
   "source": [
    "# Let's ensure all sequences have the same length through padding\n",
    "# - shorter reviews are padded with 0's\n",
    "# - longer reviews are cut\n",
    "print('Pad sequences')\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_val shape:', x_val.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1646921594926,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "sBpQpwBAk44H",
    "outputId": "194a6aad-3308-41f6-d86f-b62d22dd9440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 128)          1920000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500, 64)           8256      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 500, 64)           0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500, 64)           4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500, 64)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32000)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 32001     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,964,417\n",
      "Trainable params: 1,964,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Basic feedforward model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8c7tCS5vrC3",
    "outputId": "aab08477-7bd5-4394-b052-3faa0d266096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.4265 - accuracy: 0.7835 - val_loss: 0.2915 - val_accuracy: 0.8786\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.2425 - accuracy: 0.9045 - val_loss: 0.2745 - val_accuracy: 0.8906\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 43s 46ms/step - loss: 0.2094 - accuracy: 0.9201 - val_loss: 0.2646 - val_accuracy: 0.8975\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 43s 46ms/step - loss: 0.1903 - accuracy: 0.9269 - val_loss: 0.2773 - val_accuracy: 0.8933\n",
      "Epoch 5/20\n",
      "600/938 [==================>...........] - ETA: 14s - loss: 0.1749 - accuracy: 0.9331"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KAKOLI~1\\AppData\\Local\\Temp/ipykernel_7544/489047989.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rmsprop\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=20, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "dKBVw5mHv_oX",
    "outputId": "01b16817-5689-4137-d46b-8275b712e986"
   },
   "outputs": [],
   "source": [
    "plot_hist_classif(history)\n",
    "print('Test Accuracy = %.2f' % model.evaluate(x_test, y_test)[1])  # overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ieh7Wl9Pwh8V",
    "outputId": "7e4d2bbc-b62c-407d-ee81-e5d62d9caa3a"
   },
   "outputs": [],
   "source": [
    "# Let's try an RNN\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 64))\n",
    "model.add(layers.LSTM(128, return_sequences=False))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "Sd54xZMmxKBQ",
    "outputId": "96c092e9-eea3-4080-b720-31885daecd83"
   },
   "outputs": [],
   "source": [
    "# This model will take a long time to train, so we add an early stopping criterion\n",
    "# N.B: It's actually much faster to train WITHOUT A GPU!!\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=2)]\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=20, validation_data=(x_val, y_val), callbacks=callbacks)\n",
    "plot_hist_classif(history)\n",
    "print('Test Accuracy = %.2f' % model.evaluate(x_test, y_test)[1])\n",
    "# Note that we're still overfitting, but this is just an example of use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzZhXm5gkz_g"
   },
   "source": [
    "## Your turn!\n",
    "\n",
    "Implement a bidirectional RNN that can outperform the LSTM model we had above.\n",
    "\n",
    "A starting skeleton could be:\n",
    " \n",
    "*   Embedding layer with an output dimension of 64\n",
    "*   Bidirectional layer with a 32-neuron LSTM layer\n",
    "*   Dense layer with 1 neuron and a sigmoid activation\n",
    "\n",
    "Some suggestions:\n",
    "\n",
    "- Change the sizes of the layers (i.e., the numbers of neurons)\n",
    "- Add dropout\n",
    "- Add other recurrent and/or bidirectional layers\n",
    "\n",
    "Once you have a model that scores over 90% on the validation set, check its performance on the test set and upload it on the code checker in Moodle.\n",
    "\n",
    "Note that the model I'm suggesting above will be able to reach the desired performance, but it will show signs of overfitting. Can you do it by adding regularization (dropout, smaller network) so you don't overfit?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "executionInfo": {
     "elapsed": 904875,
     "status": "ok",
     "timestamp": 1646925200493,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "jCHOC7dyadaj",
    "outputId": "c414ef73-7d19-4d50-fa26-e0ca58c6dbc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 64)          960000    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 64)               24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 984,897\n",
      "Trainable params: 984,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/8\n",
      "938/938 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8292"
     ]
    }
   ],
   "source": [
    "n_ = 8  # number of epochs. You can edit this\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 64))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# I DON'T RECOMMEND THAT YOU CHANGE CODE AFTER THIS POINT\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# This model will take a long time to train, so we add an early stopping criterion\n",
    "# I've also added a ModelCheckpoint that will save the best model according to val_accuracy regardless of whether we continue training\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=1),\n",
    "             ModelCheckpoint(\"model.keras\", save_best_only=True, monitor=\"val_accuracy\", mode='max')]\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=n_, \n",
    "                    validation_data=(x_val, y_val), \n",
    "                    callbacks=callbacks)\n",
    "plot_hist_classif(history)\n",
    "model = keras.models.load_model(\"model.keras\")\n",
    "print('Test Accuracy = %.2f' % model.evaluate(x_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "error",
     "timestamp": 1646925200493,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "ZFBmg66_CR7y",
    "outputId": "bdf45c43-76ff-49f0-80e7-391f6abd3e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is below the threshold!\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Your model isn't accurate enough to pass the progress checker!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KAKOLI~1\\AppData\\Local\\Temp/ipykernel_7544/1630518059.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy is below the threshold!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Your model isn't accurate enough to pass the progress checker!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# Save the model into a local folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Model.h5\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Your model isn't accurate enough to pass the progress checker!"
     ]
    }
   ],
   "source": [
    "if model.count_params() > 1000000:\n",
    "    print(\"Due to memory constraints on Moodle, the lab quiz has a 10MB limit on your model size, so you need to use a smaller model to validate through the auto-marker.\")\n",
    "\n",
    "if history.history[\"val_accuracy\"][-1] > 0.9:\n",
    "    print(\"Your model is accurate enough!\")\n",
    "\n",
    "else:\n",
    "    print(\"Accuracy is below the threshold!\")\n",
    "    raise Exception(\"Your model isn't accurate enough to pass the progress checker!\")\n",
    "# Save the model into a local folder\n",
    "keras.models.save_model(model, \"Model.h5\",save_format='h5')\n",
    "print('Model saved! You can now upload it to the lab quiz.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WlhjIvZR_a0Q",
    "rloJamyvWPWj",
    "7c-duA1Z_a0R",
    "3ozUAZX__a0R"
   ],
   "name": "Copy of rnn.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/albanda/CE888/blob/master/lab8/rnn.ipynb",
     "timestamp": 1646925252038
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
